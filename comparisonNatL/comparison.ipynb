{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison between artifical language and natural language\n",
    "## A comparison between PCFG generated data and the Penn Tree Bank data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter, defaultdict\n",
    "from scipy.stats import gaussian_kde\n",
    "import numpy as np\n",
    "import matplotlib.patches as mpatches\n",
    "import os\n",
    "import string\n",
    "import scipy.optimize as opt\n",
    "import matplotlib.colors as mcolors\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PTB = []\n",
    "sentences_results_path = Path('/Users/sperdijk/Documents/Master/Jaar_3/Thesis/PTB/penn-sentences.txt')\n",
    "with open(sentences_results_path) as f:\n",
    "    for i, sentence in enumerate(f.readlines()):\n",
    "        PTB.append(sentence.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AL = []\n",
    "AL_path = Path('/Users/sperdijk/Documents/Master/Jaar_3/Thesis/thesis_code/corpora/eval.txt')\n",
    "with open(AL_path) as f:\n",
    "    for i, sentence in enumerate(f.readlines()):\n",
    "        AL.append(sentence.split(' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Length of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_dataset(dataset):\n",
    "    print(\n",
    "    f\"\"\"The length of the AL corpus is {len(dataset)}.\n",
    "    The maximum length is {max(dataset)}. \n",
    "    The minimum length is {min(dataset)}.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengthsAL = [len(i) for i in AL]\n",
    "stats_dataset(lengthsAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PTB\n",
    "cutoff_max = 20\n",
    "cutoff_min = 6\n",
    "lengthsPTB = [len(i) for i in PTB if len(i) < cutoff_max and len(i) > cutoff_min]\n",
    "stats_dataset(lengthsPTB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_length_dist(dataset, name):\n",
    "    # plot smooth distribution of sentence lengths\n",
    "    density = gaussian_kde(dataset)\n",
    "    x = np.linspace(min(dataset), max(dataset), len(dataset))\n",
    "\n",
    "    plt.hist(dataset, bins=10, density=True, alpha=0.7, label='PTB')\n",
    "    plt.plot(x, density(x), color='#FF7F0E')\n",
    "    plt.fill_between(x, density(x), alpha=0.5, color='#FF7F0E')\n",
    "    plt.xlabel('Sentence length')\n",
    "    plt.title(f'Distribution of sentence lengths of {name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_length_dist(lengthsPTB, 'PTB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_length_dist(lengthsAL, 'AL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comparison_dist(dataset1, dataset2, name1, name2):\n",
    "    # plot smooth distribution of sentence lengths\n",
    "    density1 = gaussian_kde(dataset1)\n",
    "    density2 = gaussian_kde(dataset2)\n",
    "    x1 = np.linspace(min(dataset1), max(dataset1), len(dataset1))\n",
    "    x2 = np.linspace(min(dataset2), max(dataset2), len(dataset2))\n",
    "\n",
    "    plt.plot(x1, density1(x1), color='#FF7F0E')\n",
    "    plt.fill_between(x1, density1(x1), alpha=0.5, color='#FF7F0E')\n",
    "    o_patch = mpatches.Patch(edgecolor='#FF7F0E', facecolor='#FFBF86', label=f'{name1}')\n",
    "\n",
    "    plt.plot(x2, density2(x2), color='#1F77B4', label=f'Distr of {name2}')\n",
    "    plt.fill_between(x2, density2(x2), alpha=0.5, color='#1F77B4')\n",
    "    b_patch = mpatches.Patch(edgecolor='#1F77B4', facecolor='#8FBBD9', label=f'{name2}')\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.spines[['right', 'top', 'left']].set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)   \n",
    "    plt.xlabel('Sentence length')\n",
    "    plt.title(f'Distribution of sentence lengths of {name1} and {name2}')\n",
    "    plt.legend(handles=[o_patch, b_patch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_comparison_dist(lengthsPTB, lengthsAL, 'Treebank', 'Split PCFG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zipf curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vocab(data):\n",
    "    unwantedCharacters = list(string.punctuation)\n",
    "\n",
    "    vocab = defaultdict(int)\n",
    "    # Cleaning and counting the Text\n",
    "    for text in data:\n",
    "        for word in text:\n",
    "            # Remove unwanted characters from the texts\n",
    "            if word in unwantedCharacters:\n",
    "                text.remove(word)\n",
    "                continue\n",
    "\n",
    "            vocab[word] += 1\n",
    "\n",
    "    return vocab\n",
    "\n",
    "\n",
    "def zipf_equation(x, alpha, beta):\n",
    "    return 1/(x+beta)**alpha\n",
    "\n",
    "\n",
    "def Zipf_curve(data):\n",
    "    vocab = create_vocab(data)\n",
    "\n",
    "    freq = np.zeros(len(vocab.keys()))\n",
    "    rank = np.zeros(len(vocab.keys()))\n",
    "    for i, count in enumerate(vocab.values()):\n",
    "        sample = np.random.binomial(count, 0.5)\n",
    "        freq[i] = sample\n",
    "        rank[i] = count - sample\n",
    "    \n",
    "    indices = np.argsort(rank)[::-1]\n",
    "    rank = np.sort(rank[::-1])\n",
    "    freq = freq[indices]\n",
    "    freq = freq / np.linalg.norm(freq)\n",
    "    x_values = np.arange(1, len(vocab.keys())+1)\n",
    "\n",
    "    # Fit Eq. 2 to the data\n",
    "    params, _ = opt.curve_fit(zipf_equation, x_values, freq, maxfev=10000)\n",
    "\n",
    "    # Generate fitted line\n",
    "    fitted_line = zipf_equation(x_values, *params)\n",
    "\n",
    "    return x_values, freq, fitted_line, params\n",
    "\n",
    "def plot_Zipf_curve_comparison(data1, data2, name1, name2):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 4))\n",
    "    data = [data1, data2]\n",
    "    names = [name1, name2]\n",
    "\n",
    "    # define color schema\n",
    "    colors = [\"blue\", \"lightgreen\"]\n",
    "    cmap = mcolors.LinearSegmentedColormap.from_list(\"custom_cmap\", colors, N=100)\n",
    "\n",
    "    for i, ax in enumerate([ax1, ax2]):\n",
    "        # get the distribution over the data and the Zipf curve\n",
    "        x_values, y_values, fitted_line, params = Zipf_curve(data[i])\n",
    "\n",
    "        # plot the data and the fitted line\n",
    "        ax.hexbin(np.log(x_values), np.log(y_values), gridsize=70, cmap=cmap, bins='log')\n",
    "        ax.plot(np.log(x_values), np.log(fitted_line), color='red')\n",
    "\n",
    "        # display the parameters of the fitted line\n",
    "        ax.text(0.1, 0.05, f'α = {params[0]:.2f}\\nβ = {params[1]:.2f}', transform=ax.transAxes, fontsize=8)\n",
    "\n",
    "        # Customize the plots\n",
    "        ax.set_xticks(np.arange(0, 12, 2))\n",
    "        ax.tick_params(axis='both', which='both', labelcolor='gray', bottom=False, left=False)\n",
    "        ax.spines[['right', 'top']].set_visible(False)\n",
    "\n",
    "        # Labeling the plot\n",
    "        ax.set_xlabel('Log frequency rank')\n",
    "        ax.set_ylabel('Log normalized frequency')\n",
    "\n",
    "        ax.set_title(f'{names[i]}')\n",
    "\n",
    "    ax2.yaxis.get_label().set_visible(False)\n",
    "\n",
    "def plot_Zipf_curve(data):\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    colors = [\"blue\", \"lightgreen\"]\n",
    "    cmap = mcolors.LinearSegmentedColormap.from_list(\"custom_cmap\", colors, N=100)\n",
    "\n",
    "    x_values, y_values, fitted_line, _ = Zipf_curve(data)\n",
    "\n",
    "    # plot the data and the fitted line\n",
    "    plt.hexbin(np.log(x_values), np.log(y_values), gridsize=70, cmap=cmap, bins='log')\n",
    "    plt.plot(np.log(x_values), np.log(fitted_line), color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_Zipf_curve_comparison(PTB, AL, 'Original TreeBank', 'Split PCFG corpus')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shared levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in shared_levels_PTB.txt\n",
    "shared_levels_path = Path('/Users/sperdijk/Documents/Master/Jaar_3/Thesis/thesis_code/data/shared_levels_PTB.txt')\n",
    "with open(shared_levels_path) as f:\n",
    "    shared_levels = f.readlines()\n",
    "\n",
    "skipped_idx = []\n",
    "for i, sentence in enumerate(PTB):\n",
    "    if len(sentence) >= cutoff_max or len(sentence) <= cutoff_min:\n",
    "        skipped_idx.append(i)\n",
    "\n",
    "shared_levels = [i for j, i in enumerate(shared_levels) if j not in skipped_idx]\n",
    "shared_levelsPTB = [int(l.replace('\\n', '')) for sentence in shared_levels for l in sentence.split(' ') if l != '\\n']\n",
    "len(shared_levelsPTB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_levels_path = Path('/Users/sperdijk/Documents/Master/Jaar_3/Thesis/thesis_code/data/train_shared_withoutROOT.txt')\n",
    "with open(shared_levels_path) as f:\n",
    "    shared_levels = f.readlines()\n",
    "\n",
    "shared_levelsPCFG = [int(l.replace('\\n', '')) for sentence in shared_levels for l in sentence.split(' ') if l != '\\n']\n",
    "len(shared_levelsPCFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_shared_levels(data, name):\n",
    "    print(\n",
    "        f\"\"\"\n",
    "        {name:}\n",
    "        The amount of labels is {len(data)}.\n",
    "        There are {len(set(data))} unique labels.\n",
    "        The labels are: {set(data)}.\n",
    "        \"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_shared_levels(shared_levelsPTB, name='PTB')\n",
    "stats_shared_levels(shared_levelsPCFG, name='PCFG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_shared_levels(datasets, names):\n",
    "    plt.hist(datasets[0], density=True, alpha=0.7, label=names[0])\n",
    "    plt.hist(datasets[1], density=True, alpha=0.7, label=names[1])\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.spines[['right', 'top', 'left']].set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False) \n",
    "\n",
    "    plt.xlabel('Relative shared levels')\n",
    "    plt.title('Relative shared levels of PTB and PCFG')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_shared_levels([shared_levelsPTB, shared_levelsPCFG], ['PTB', 'PCFG'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunking (distribution BIES labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
