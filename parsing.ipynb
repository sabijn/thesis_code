{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-f76456d37d71>:14: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for line in tqdm_notebook(lines[:]):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af888e1e7a2a49b88ac217f3e54c405a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-f76456d37d71>:22: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for lhs, rhs_counter in tqdm_notebook(prod_dict.items()):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d49175aa6594ec9ae6f5b164a5c8ded",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nltk import CFG\n",
    "from collections import Counter, defaultdict\n",
    "import nltk\n",
    "from nltk import ProbabilisticProduction, PCFG, Nonterminal\n",
    "from tqdm import *\n",
    "\n",
    "\n",
    "# with open(\"../ptb/penn-wsj-line.txt\") as f:\n",
    "with open(\"/home/jaap/Documents/AI/diagnosing_lms/experiments/explain-lm/books/cleaned_parsed_corpus_part1/500k_parse_trees.txt\") as f:    \n",
    "    lines = [l.strip() for l in f.readlines()]\n",
    "\n",
    "\n",
    "prod_dict = defaultdict(Counter)\n",
    "for line in tqdm_notebook(lines[:]):\n",
    "    tree = nltk.Tree.fromstring(line)\n",
    "    for prod in tree.productions():\n",
    "        prod_dict[prod.lhs()][prod.rhs()] += 1\n",
    "    \n",
    "\n",
    "prob_productions = []\n",
    "\n",
    "for lhs, rhs_counter in tqdm_notebook(prod_dict.items()):\n",
    "    total_counts = sum(rhs_counter.values())\n",
    "    rhs_probs = {\n",
    "        rhs: count / total_counts\n",
    "        for rhs, count in rhs_counter.items()\n",
    "    }\n",
    "    \n",
    "    for rhs, prob in rhs_probs.items():\n",
    "        prob_productions.append(\n",
    "            ProbabilisticProduction(lhs, rhs, prob=prob)\n",
    "        )\n",
    "\n",
    "start = Nonterminal('S')        \n",
    "pcfg = PCFG(start, prob_productions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcfg._lhs_prob_index = {}\n",
    "for lhs in pcfg._lhs_index.keys():\n",
    "    lhs_probs = [prod.prob() for prod in pcfg.productions(lhs=lhs)]\n",
    "    pcfg._lhs_prob_index[lhs] = lhs_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Grammar with 112842 productions>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-8e7a334dc902>:50: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for _ in tqdm_notebook(range(450_000*2)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30411744280d4c86850b81064210713b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/900000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "141387"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "from tqdm import *\n",
    "\n",
    "\n",
    "def generate_tree(grammar, start=None, depth=None, max_tries=10) -> nltk.Tree:\n",
    "    if not start:\n",
    "        start = grammar.start()\n",
    "    if depth is None:\n",
    "        depth = 100\n",
    "\n",
    "    for _ in range(max_tries):\n",
    "        try:\n",
    "            tree_str = concatenate_subtrees(grammar, [start], depth)\n",
    "            return nltk.Tree.fromstring(tree_str)\n",
    "        except RecursionError:\n",
    "            pass\n",
    "\n",
    "    raise ValueError(\"No tree could be generated with current depth\")\n",
    "\n",
    "\n",
    "def concatenate_subtrees(grammar, items, depth):\n",
    "    if items:\n",
    "        children = []\n",
    "        for item in items:\n",
    "            children.append(generate_subtree(grammar, item, depth))\n",
    "\n",
    "        return \" \".join(children)\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "\n",
    "def generate_subtree(grammar, lhs, depth):\n",
    "    if depth > 0:\n",
    "        if isinstance(lhs, Nonterminal):\n",
    "            productions = grammar.productions(lhs=lhs)\n",
    "            probs = grammar._lhs_prob_index[lhs]\n",
    "\n",
    "            for prod in random.choices(productions, probs, k=1):\n",
    "                children = concatenate_subtrees(grammar, prod.rhs(), depth - 1)\n",
    "                return f\"({lhs.symbol()} {children})\"\n",
    "        else:\n",
    "            return lhs\n",
    "    else:\n",
    "        raise RecursionError\n",
    "\n",
    "\n",
    "corpus = []\n",
    "length = 450_000\n",
    "\n",
    "for _ in tqdm_notebook(range(450_000*2)):\n",
    "    string = generate_tree(pcfg, depth=30)[0].leaves()\n",
    "    if 6 <= len(string) <= 25:\n",
    "        corpus.append(' '.join(string))\n",
    "    \n",
    "    if len(corpus) >= 450_000:\n",
    "        break\n",
    "\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('raw_pcfg_corpus2.txt', 'w') as f:\n",
    "    f.write('\\n'.join(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRODS_SEEN = set()  # to prevent recursion\n",
    "\n",
    "\n",
    "def create_subset_productions(productions, top_k):\n",
    "    subset_productions = []\n",
    "\n",
    "    prob_productions_dict = defaultdict(list)\n",
    "    for prod in productions:\n",
    "        prob_productions_dict[prod.lhs()].append(prod)\n",
    "\n",
    "    for lhs, lhs_prods in prob_productions_dict.items():\n",
    "        sorted_rhs = sorted(\n",
    "            lhs_prods,\n",
    "            key=lambda prod: -prod.prob(),\n",
    "        )\n",
    "        sorted_rhs = [\n",
    "            prod for prod in sorted_rhs if (\n",
    "                # Nonterminal('-NONE-') not in prod.rhs()\n",
    "                and prod.lhs() not in prod.rhs()\n",
    "                # and '%' not in prod.rhs()\n",
    "            )\n",
    "        ]\n",
    "        if isinstance(top_k, int):\n",
    "            subset_rhs = sorted_rhs[:top_k]\n",
    "\n",
    "        elif isinstance(top_k, float):\n",
    "            acc_prob = 0.\n",
    "            subset_rhs = []\n",
    "            for prod in sorted_rhs:\n",
    "                subset_rhs.append(prod)\n",
    "                acc_prob += prod.prob()\n",
    "                if acc_prob > top_k:\n",
    "                    break\n",
    "\n",
    "        subset_productions.extend(subset_rhs)\n",
    "\n",
    "    return subset_productions\n",
    "\n",
    "\n",
    "def is_leaf(prod):\n",
    "    return len(prod.rhs()) == 1 and isinstance(prod.rhs()[0], str)\n",
    "\n",
    "\n",
    "def reachable_productions(productions, lhs, parents=tuple(), no_recursion=False):\n",
    "    new_parents = (*parents, lhs)\n",
    "\n",
    "    lhs_productions = [prod for prod in productions if prod.lhs() == lhs]\n",
    "    \n",
    "    for prod in lhs_productions:\n",
    "        if (prod,) in PRODS_SEEN:\n",
    "            continue\n",
    "        PRODS_SEEN.add((prod,))\n",
    "            \n",
    "        if no_recursion and any([rhs in parents for rhs in prod.rhs()]):\n",
    "            continue\n",
    "\n",
    "        yield prod\n",
    "\n",
    "        for rhs in prod.rhs():\n",
    "            if isinstance(rhs, Nonterminal):\n",
    "                yield from reachable_productions(\n",
    "                    productions, \n",
    "                    rhs, \n",
    "                    parents=new_parents,\n",
    "                    no_recursion=no_recursion,\n",
    "                )\n",
    "\n",
    "                \n",
    "def leaves_to_pos(prods):\n",
    "    return set(\n",
    "        ProbabilisticProduction(\n",
    "            prod.lhs(), \n",
    "            (prod.lhs().symbol().lower(),), \n",
    "            prob=1.0,\n",
    "        )\n",
    "        if is_leaf(prod)\n",
    "        else prod\n",
    "        for prod in prods\n",
    "    )\n",
    "                \n",
    "                \n",
    "def renormalize_probs(prods):\n",
    "    new_prods = []\n",
    "    all_lhs = set(prod.lhs() for prod in prods)\n",
    "    \n",
    "    for lhs in all_lhs:\n",
    "        lhs_prods = [prod for prod in prods if prod.lhs() == lhs]\n",
    "        \n",
    "        lhs_total_prob = sum(prod.prob() for prod in lhs_prods)\n",
    "        \n",
    "        for prod in lhs_prods:\n",
    "            new_prob = prod.prob() / lhs_total_prob\n",
    "            new_prods.append(\n",
    "                ProbabilisticProduction(prod.lhs(), prod.rhs(), prob=new_prob)\n",
    "            )\n",
    "            \n",
    "    return new_prods\n",
    "\n",
    "\n",
    "def create_subset_pcfg(productions, top_k=0.2, no_recursion=False):\n",
    "    subset_productions = create_subset_productions(productions)\n",
    "    \n",
    "    final_subset_productions = set(\n",
    "        reachable_productions(\n",
    "            subset_productions, \n",
    "            start, \n",
    "            no_recursion=no_recursion,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # update set for removed recursive productions\n",
    "    reachable_nonterminals = set(prod.lhs() for prod in final_subset_productions)\n",
    "    final_subset_productions = [\n",
    "        prod for prod in final_subset_productions \n",
    "        if all([rhs in reachable_nonterminals for rhs in prod.rhs()]) or is_leaf(prod)\n",
    "    ]\n",
    "    final_subset_productions = renormalize_probs(final_subset_productions)\n",
    "\n",
    "    pos_productions = leaves_to_pos(final_subset_productions)\n",
    "    pos_productions = renormalize_probs(pos_productions)\n",
    "\n",
    "    subset_pcfg = PCFG(start, final_subset_productions)\n",
    "    subset_pcfg_pos = PCFG(start, pos_productions)\n",
    "\n",
    "    return subset_pcfg, subset_pcfg_pos\n",
    "\n",
    "\n",
    "# with open(f\"pcfg_langs/{top_k}_pcfg_words.txt\", \"w\") as f:\n",
    "#     f.write(\"\\n\".join(map(str, final_subset_productions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he proceed businesses official . \n",
      "\n",
      "*-1 away all company to to to to was Peter 16 . \n",
      "\n",
      "next is what government-owned workers designed 0 Try to a senior profitability . . \n",
      "\n",
      "The result attached His trade as Florida \n",
      "\n",
      "* closely to attached \n",
      "\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "it is the business said of it going the issue \n",
      "\n",
      "it is the price said of it was the issue \n",
      "\n",
      "it expected the good plan \n",
      "\n",
      "it have group \n",
      "\n",
      "it according the plan \n",
      "\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "dt nn vbd in prp vbd dt nn vbz prp vb dt nn \n",
      "\n",
      "prp vbd prp vbd dt jj nn \n",
      "\n",
      "prp vb dt jj nn \n",
      "\n",
      "prp vbz dt nn vb nns \n",
      "\n",
      "prp vbg dt nn \n",
      "\n",
      "prp vbg dt nn \n",
      "\n",
      "prp vbd in dt nn vbd in prp vbg dt nn \n",
      "\n",
      "prp vbg nns \n",
      "\n",
      "prp vbn dt nn \n",
      "\n",
      "prp vbd in prp vbz prp vbd nns \n",
      "\n",
      "prp vbd nns \n",
      "\n",
      "dt nn vbg dt nn \n",
      "\n",
      "prp vbd in prp vbd nn \n",
      "\n",
      "dt nn vbn dt nn \n",
      "\n",
      "prp vb dt nn \n",
      "\n",
      "prp vbn nns \n",
      "\n",
      "prp vbd prp vbz prp vb nns \n",
      "\n",
      "prp vbd dt nn \n",
      "\n",
      "prp vbd in dt nn vbd prp vbd prp vbz nns \n",
      "\n",
      "prp vb dt nn \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.grammar import Nonterminal\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "\n",
    "def generate_pcfg(grammar, start=None, depth=None, n=None):\n",
    "    if not start:\n",
    "        start = grammar.start()\n",
    "    if depth is None:\n",
    "        depth = 1_000\n",
    "\n",
    "    iterator = _generate_all_pcfg(grammar, [start], depth)\n",
    "\n",
    "    if n:\n",
    "        iterator = itertools.islice(iterator, n)\n",
    "\n",
    "    return iterator\n",
    "\n",
    "\n",
    "def _generate_all_pcfg(grammar, items, depth):\n",
    "    if items:\n",
    "        for frag1 in _generate_one_pcfg(grammar, items[0], depth):\n",
    "            for frag2 in _generate_all_pcfg(grammar, items[1:], depth):\n",
    "                yield frag1 + frag2\n",
    "    else:\n",
    "        yield []\n",
    "\n",
    "\n",
    "def _generate_one_pcfg(grammar, item, depth):\n",
    "    if depth > 0:\n",
    "        if isinstance(item, Nonterminal):\n",
    "            productions = grammar.productions(lhs=item)\n",
    "            probs = [rule.prob() for rule in productions]\n",
    "\n",
    "            for prod in random.choices(productions, probs, k=depth):\n",
    "                yield from _generate_all_pcfg(grammar, prod.rhs(), depth - 1)\n",
    "        else:\n",
    "            yield [item]\n",
    "    else:\n",
    "        yield []\n",
    "        \n",
    "        \n",
    "\n",
    "for _ in range(5):\n",
    "    for string in generate_pcfg(pcfg, depth=100):\n",
    "        print(\" \".join(string), \"\\n\")\n",
    "        break\n",
    "        \n",
    "print('-'*100, '\\n')\n",
    "\n",
    "for _ in range(5):\n",
    "    for string in generate_pcfg(subset_pcfg, depth=100):\n",
    "        print(\" \".join(string), \"\\n\")\n",
    "        break\n",
    "        \n",
    "print('-'*100, '\\n')\n",
    "\n",
    "for _ in range(20):\n",
    "    for string in generate_pcfg(subset_pcfg_pos, depth=100):\n",
    "        print(\" \".join(string), \"\\n\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(S\n",
      "  (NP-SBJ (DT dt) (NN nn))\n",
      "  (VP (VBP vbp) (NP (DT dt) (ADJP (JJ jj)) (NN nn))))\n",
      "2\n",
      "(S\n",
      "  (NP-SBJ (DT dt) (NN nn))\n",
      "  (VP (VBP vbp) (NP (DT dt) (JJ jj) (NN nn))))\n",
      "3\n",
      "(S\n",
      "  (NP-SBJ (DT dt) (NN nn))\n",
      "  (VP (VBP vbp) (NP-PRD (DT dt) (JJ jj) (NN nn))))\n"
     ]
    }
   ],
   "source": [
    "from nltk.parse import ChartParser\n",
    "\n",
    "\n",
    "srp = ChartParser(subset_pcfg_pos)\n",
    "\n",
    "sen = \"dt nn vbp dt jj nn\".split()\n",
    "i = 1\n",
    "for parse in srp.parse(sen):\n",
    "    print(i)\n",
    "    print(parse)\n",
    "    i += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
