{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import ProbabilisticProduction, PCFG, Nonterminal\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "from typing import List, Tuple, Dict, Any\n",
    "import itertools\n",
    "from collections import Counter, defaultdict\n",
    "import pickle\n",
    "import os\n",
    "from nltk import PCFG as nltk_PCFG\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dark mode tqdm notebook progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".cell-output-ipywidget-background {\n",
       "    background-color: transparent !important;\n",
       "}\n",
       ":root {\n",
       "    --jp-widgets-color: var(--vscode-editor-foreground);\n",
       "    --jp-widgets-font-size: var(--vscode-editor-font-size);\n",
       "}  \n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    ".cell-output-ipywidget-background {\n",
    "    background-color: transparent !important;\n",
    "}\n",
    ":root {\n",
    "    --jp-widgets-color: var(--vscode-editor-foreground);\n",
    "    --jp-widgets-font-size: var(--vscode-editor-font-size);\n",
    "}  \n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate raw pcfg and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_treebank(filename=\"treebanks/original_treebank_500k.txt\"):\n",
    "    \"\"\"\n",
    "    Read in the google books treebank (default)\n",
    "    \"\"\"\n",
    "    with open(filename) as f:    \n",
    "        lines = [l.strip() for l in f.readlines()]\n",
    "    \n",
    "    return lines\n",
    "\n",
    "def get_productions(treebank):\n",
    "    \"\"\"\n",
    "    Return the counts of the productions from the treebank. \n",
    "    Tree.productions() returns a list of productions (lhs, rhs) where lhs is a Nonterminal and rhs is a tuple of Nonterminals and strings (terminals)\n",
    "    \"\"\"\n",
    "    prod_dict = defaultdict(Counter)\n",
    "    for line in tqdm(treebank[:]):\n",
    "        tree = nltk.Tree.fromstring(line)\n",
    "\n",
    "        for prod in tree.productions():\n",
    "            prod_dict[prod.lhs()][prod.rhs()] += 1\n",
    "\n",
    "    return prod_dict\n",
    "\n",
    "def calculate_prob_productions(prod_dict):\n",
    "    \"\"\"\n",
    "    Calculate the probabilities of each productions given the counts.\n",
    "    \"\"\"\n",
    "    prob_productions = []\n",
    "\n",
    "    for lhs, rhs_counter in tqdm(prod_dict.items()):\n",
    "        total_counts = sum(rhs_counter.values())\n",
    "        rhs_probs = {\n",
    "            rhs: count / total_counts\n",
    "            for rhs, count in rhs_counter.items()\n",
    "        }\n",
    "        \n",
    "        for rhs, prob in rhs_probs.items():\n",
    "            prob_productions.append(\n",
    "                ProbabilisticProduction(lhs, rhs, prob=prob)\n",
    "            )\n",
    "    \n",
    "    return prob_productions\n",
    "\n",
    "def create_lookup_probs(pcfg):\n",
    "    \"\"\"\n",
    "    Create probability lookup table\n",
    "    \"\"\"\n",
    "    pcfg._lhs_prob_index = {}\n",
    "    for lhs in pcfg._lhs_index.keys():\n",
    "        lhs_probs = [prod.prob() for prod in pcfg.productions(lhs=lhs)]\n",
    "        pcfg._lhs_prob_index[lhs] = lhs_probs\n",
    "    \n",
    "    return pcfg\n",
    "\n",
    "def write_to_pickle(file, filename='grammars/nltk/raw_pcfg.pkl'):\n",
    "    \"\"\"\n",
    "    Write the pcfg to a pickle file\n",
    "    \"\"\"\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(file, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_raw_pcfg(filename='grammars/nltk/raw_pcfg.pkl'):\n",
    "    \"\"\"\n",
    "    Create a raw pcfg from the treebank and save it to a pickle file (if it doesn't exist already)\n",
    "    \"\"\"\n",
    "    if os.path.exists(filename):\n",
    "        with open(filename, 'rb') as f:\n",
    "            pcfg, prob_productions = pickle.load(f)\n",
    "            return pcfg, prob_productions\n",
    "        \n",
    "    treebank = read_treebank()\n",
    "    prod_dict = get_productions(treebank)\n",
    "\n",
    "    prob_productions = calculate_prob_productions(prod_dict)\n",
    "\n",
    "    start = Nonterminal('S')        \n",
    "    pcfg = PCFG(start, prob_productions)\n",
    "\n",
    "    pcfg = create_lookup_probs(pcfg)\n",
    "    write_to_pickle((pcfg, prob_productions))\n",
    "\n",
    "    return pcfg, prob_productions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Grammar with 112842 productions>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcfg, prob_productions = create_raw_pcfg()\n",
    "pcfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate trees from pcfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tree(grammar, start=None, depth=None, max_tries=10) -> nltk.Tree:\n",
    "    \"\"\"\n",
    "    Generate a single tree from the grammar with a given start symbol and depth.\n",
    "    Returns a tree or a ValueError if no tree could be generated.\n",
    "    \"\"\"\n",
    "    if not start:\n",
    "        start = grammar.start()\n",
    "    if depth is None:\n",
    "        depth = 100\n",
    "\n",
    "    for _ in range(max_tries):\n",
    "        try:\n",
    "            tree_str = concatenate_subtrees(grammar, [start], depth)\n",
    "            return nltk.Tree.fromstring(tree_str)\n",
    "        except RecursionError:\n",
    "            pass\n",
    "\n",
    "    raise ValueError(\"No tree could be generated with current depth\")\n",
    "\n",
    "\n",
    "def concatenate_subtrees(grammar, items, depth):\n",
    "    \"\"\"\n",
    "    Generates a subtree for each item of the list and concatenates them.\n",
    "    Returns a string representation of the subtree or an empty list if no items are given.\n",
    "    \"\"\"\n",
    "    if items:\n",
    "        children = []\n",
    "        for item in items:\n",
    "            children.append(generate_subtree(grammar, item, depth))\n",
    "\n",
    "        return \" \".join(children)\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "\n",
    "def generate_subtree(grammar, lhs, depth):\n",
    "    \"\"\"\n",
    "    Given a left hand non terminal, generate a right had side with a given probability\n",
    "    \"\"\"\n",
    "    if depth > 0:\n",
    "        if isinstance(lhs, Nonterminal):\n",
    "            # get all possible rules containing this lhs\n",
    "            productions = grammar.productions(lhs=lhs)\n",
    "            # get probabilities of rules\n",
    "            probs = grammar._lhs_prob_index[lhs]\n",
    "\n",
    "            # Choose a production based on the probabilities (k = amount of samples)\n",
    "            for prod in random.choices(productions, probs, k=1):\n",
    "                children = concatenate_subtrees(grammar, prod.rhs(), depth - 1)\n",
    "                \n",
    "                return f\"({lhs.symbol()} {children})\"\n",
    "        else:\n",
    "            # lhs is a terminal and should not have children\n",
    "            return lhs\n",
    "    else:\n",
    "        raise RecursionError\n",
    "    \n",
    "def generate_corpus_from_pcfg(pcfg, corpus_length=450_000, depth=30, sentence_length=(6, 25)) -> list:\n",
    "    \"\"\"\n",
    "    Generate a corpus of sentences with a given length from a PCFG\n",
    "    \"\"\"\n",
    "    corpus = []\n",
    "    emergency_stop = 0\n",
    "\n",
    "    while len(corpus) < corpus_length:\n",
    "        sentence = generate_tree(pcfg, depth=depth)\n",
    "        if sentence_length[0] <= len(sentence.leaves()) <= sentence_length[1]:\n",
    "            corpus.append(\" \".join(sentence.leaves()))\n",
    "\n",
    "        emergency_stop += 1\n",
    "        if emergency_stop % 100_000 == 0:\n",
    "            print(f\"Current corpus length: {len(corpus)}\")\n",
    "            \n",
    "        elif emergency_stop > 1_000_000:\n",
    "            print(\"Emergency stop. Could not generate enough sentences.\")\n",
    "            break\n",
    "    \n",
    "    return corpus\n",
    "\n",
    "\n",
    "def write_to_txtfile(corpus, filename=\"corpora/raw_pcfg_corpus.txt\"):\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write('\\n'.join(corpus))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_corpus(pcfg, filename=\"corpora/raw_pcfg_corpus.txt\"):\n",
    "    if os.path.exists(filename):\n",
    "        with open(filename) as f:\n",
    "            corpus = [l.strip('\\n') for l in f.readlines()]\n",
    "        \n",
    "        return corpus\n",
    "    \n",
    "    corpus = generate_corpus_from_pcfg(pcfg)\n",
    "    write_to_txtfile(corpus)\n",
    "\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "450000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = load_corpus(pcfg)\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prune raw PCFG (i.e. create sub pcfgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a 'parent' PCFG, either:\n",
    "- Remove the tail of probability productions ``(type(top_k) = int)``\n",
    "- Keep a part of the probability mass ``(type(top_k) = float)``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select subset of pcfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRODS_SEEN = set()  # to prevent recursion\n",
    "\n",
    "def sort_and_select_productions(rhs_prods, top_k):\n",
    "    \"\"\"\n",
    "    Sort rhs probabilities and select top_k productions.\n",
    "    \"\"\"\n",
    "    sorted_rhs = sorted(rhs_prods, key=lambda prod: -prod.prob())\n",
    "    \n",
    "    # Remove recursive productions\n",
    "    # TODO: ask Jaap if here should be a recursion flag?\n",
    "    sorted_rhs = [prod for prod in sorted_rhs if (prod.lhs() not in prod.rhs())]\n",
    "    \n",
    "    # Select top_k productions\n",
    "    if isinstance(top_k, int):\n",
    "        subset_rhs = sorted_rhs[:top_k]\n",
    "\n",
    "    # Select top_k productions based on probability\n",
    "    elif isinstance(top_k, float):\n",
    "        acc_prob = 0.\n",
    "        subset_rhs = []\n",
    "        for prod in sorted_rhs:\n",
    "            subset_rhs.append(prod)\n",
    "            acc_prob += prod.prob()\n",
    "            if acc_prob > top_k:\n",
    "                break\n",
    "    \n",
    "    return subset_rhs\n",
    "\n",
    "def group_productions_by_lhs(productions):\n",
    "    \"\"\"\n",
    "    Group productions by their left-hand side symbol.\n",
    "    \"\"\"\n",
    "    lhs_productions = defaultdict(list)\n",
    "    for prod in productions:\n",
    "        lhs_productions[prod.lhs()].append(prod)\n",
    "\n",
    "    return lhs_productions\n",
    "\n",
    "\n",
    "def create_subset_productions(productions, top_k):\n",
    "    \"\"\"\n",
    "    Given a list of productions, create a subset of productions by selecting the top_k most probable productions.\n",
    "    \"\"\"\n",
    "    subset_productions = []\n",
    "\n",
    "    # Group productions by their left-hand side\n",
    "    prob_productions_dict = group_productions_by_lhs(productions)\n",
    "\n",
    "    # Sort productions by probability (from high to low) and select top_k (for each left-hand side symbol)\n",
    "    for rhs_prods in prob_productions_dict.values():\n",
    "        subset_rhs = sort_and_select_productions(rhs_prods, top_k)\n",
    "        subset_productions.extend(subset_rhs)\n",
    "\n",
    "    return subset_productions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if selected subset is valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reachable_productions(productions, lhs, parents=tuple(), no_recursion=False):\n",
    "    \"\"\"\n",
    "    Create a generator that yields all reachable productions from a given lhs symbol.\n",
    "    \"\"\"\n",
    "    # reminder: *(tuple) unpacks the tuple into arguments\n",
    "    new_parents = (*parents, lhs)\n",
    "    \n",
    "    # select productions belonging to the current lhs\n",
    "    lhs_productions = [prod for prod in productions if prod.lhs() == lhs]\n",
    "    \n",
    "    for prod in lhs_productions:\n",
    "        if (prod,) in PRODS_SEEN:\n",
    "            continue\n",
    "        PRODS_SEEN.add((prod,))\n",
    "\n",
    "        # check if the rhs contains a parent symbol    \n",
    "        if no_recursion and any([rhs in parents for rhs in prod.rhs()]):\n",
    "            continue\n",
    "\n",
    "        yield prod\n",
    "\n",
    "        for rhs in prod.rhs():\n",
    "            if isinstance(rhs, Nonterminal):\n",
    "                yield from reachable_productions(\n",
    "                    productions, \n",
    "                    rhs, \n",
    "                    parents=new_parents,\n",
    "                    no_recursion=no_recursion,\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renormalize productions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def renormalize_probs(prods):\n",
    "    \"\"\"\n",
    "    Renomalize probabilities of productions for each left-hand side symbol.\n",
    "    \"\"\"\n",
    "    new_prods = []\n",
    "    all_lhs = set(prod.lhs() for prod in prods)\n",
    "    \n",
    "    for lhs in all_lhs:\n",
    "        lhs_prods = [prod for prod in prods if prod.lhs() == lhs]\n",
    "        \n",
    "        lhs_total_prob = sum(prod.prob() for prod in lhs_prods)\n",
    "        \n",
    "        for prod in lhs_prods:\n",
    "            new_prob = prod.prob() / lhs_total_prob\n",
    "            new_prods.append(\n",
    "                ProbabilisticProduction(prod.lhs(), prod.rhs(), prob=new_prob)\n",
    "            )\n",
    "            \n",
    "    return new_prods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate pos tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_leaf(prod):\n",
    "    \"\"\"\n",
    "    Check if a production is a leaf (i.e. has only one rhs symbol which is a string)\n",
    "    \"\"\"\n",
    "    return len(prod.rhs()) == 1 and isinstance(prod.rhs()[0], str)\n",
    "\n",
    "\n",
    "def leaves_to_pos(prods):\n",
    "    \"\"\"\n",
    "    Labels each leaf with its POS tag (with a probability of 1.0)\n",
    "    \"\"\"\n",
    "    return set(ProbabilisticProduction(prod.lhs(), \n",
    "                                       (prod.lhs().symbol().lower(),), \n",
    "                                       prob=1.0) if is_leaf(prod) else prod for prod in prods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main: generate subset pcfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_subset_pcfg(productions, top_k=0.2, no_recursion=False):\n",
    "    \"\"\"\n",
    "    Create a subset PCFG from the original PCFG by selecting the top_k most probable productions.\n",
    "    \"\"\"\n",
    "    start = Nonterminal('S_0')\n",
    "\n",
    "    print(f'************ Creating subset PCFG with top k = {top_k}... ************', flush=True)\n",
    "    print(f'Starting with {len(productions)} productions.', flush=True)\n",
    "    subset_productions = create_subset_productions(productions, top_k)\n",
    "    # for prod in subset_productions:\n",
    "    #     print(f'{prod}' + '\\n')\n",
    "    print(f'Created subset PCFG with a length of {len(subset_productions)} productions.', flush=True)\n",
    "\n",
    "    print('Cleaning subset: (1) removing unreachable productions...')\n",
    "    final_subset_productions = set(\n",
    "        reachable_productions(\n",
    "            subset_productions, \n",
    "            start, \n",
    "            no_recursion=no_recursion,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # update set for removed recursive productions\n",
    "    reachable_nonterminals = set(prod.lhs() for prod in final_subset_productions)\n",
    "    print('Amount of reachable nonterminals:', len(reachable_nonterminals))\n",
    "    final_subset_productions = [\n",
    "        prod for prod in final_subset_productions \n",
    "        if all([rhs in reachable_nonterminals for rhs in prod.rhs()]) or is_leaf(prod)\n",
    "    ]\n",
    "    print(f'Finished cleaning subset (1) left with {len(final_subset_productions)} productions.')\n",
    "\n",
    "    print('Cleaning subset: (2) renormalizing probabilities...')\n",
    "    final_subset_productions = renormalize_probs(final_subset_productions)\n",
    "    print(f'Finished cleaning subset (2)')\n",
    "\n",
    "    print('Cleaning subset: (3) adding POS tags...')\n",
    "    pos_productions = leaves_to_pos(final_subset_productions)\n",
    "    pos_productions = renormalize_probs(pos_productions)\n",
    "    print('Finished cleaning subset (3)')\n",
    "\n",
    "    # subset_pcfg does not contain pos_tags\n",
    "    subset_pcfg = PCFG(start, final_subset_productions)\n",
    "    subset_pcfg_pos = PCFG(start, pos_productions)\n",
    "    \n",
    "    print('Write subset PCFG to pickle...')\n",
    "    write_to_pickle(subset_pcfg, f'grammars/nltk/subset_pcfg_{top_k}.pkl')\n",
    "    write_to_pickle(subset_pcfg_pos, f'grammars/nltk/subset_pcfg_{top_k}_pos.pkl')\n",
    "    print('Done')\n",
    "    \n",
    "    return subset_pcfg, subset_pcfg_pos\n",
    "\n",
    "def load_subset_pcfg(prob_productions, top_k=0.2):\n",
    "    filename = f'grammars/nltk/subset_pcfg_{top_k}.pkl'\n",
    "    filename_pos = f'grammars/nltk/subset_pcfg_{top_k}_pos.pkl'\n",
    "    \n",
    "    if os.path.exists(filename) and os.path.exists(filename_pos):\n",
    "        with open(filename, 'rb') as f:\n",
    "            subset_pcfg = pickle.load(f)\n",
    "        \n",
    "        with open(filename_pos, 'rb') as f:\n",
    "            subset_pcfg_pos = pickle.load(f)\n",
    "\n",
    "        return subset_pcfg, subset_pcfg_pos\n",
    "    \n",
    "    subset_pcfg, subset_pcfg_pos = create_subset_pcfg(prob_productions, top_k)\n",
    "\n",
    "    return subset_pcfg, subset_pcfg_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create sentences from pcfgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions share some functionalies with the functions in [Generate trees from pcfg](#generate-trees-from-pcfg).  \n",
    "However, the functions below return an iterator which makes it possible to generate parts of sentences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pcfg(grammar, start=None, depth=None, n=None):\n",
    "    if not start:\n",
    "        start = grammar.start()\n",
    "    if depth is None:\n",
    "        depth = 1_000\n",
    "\n",
    "    iterator = _generate_all_pcfg(grammar, [start], depth)\n",
    "\n",
    "    if n:\n",
    "        iterator = itertools.islice(iterator, n)\n",
    "\n",
    "    return iterator\n",
    "\n",
    "\n",
    "def _generate_all_pcfg(grammar, items, depth):\n",
    "    if items:\n",
    "        for frag1 in _generate_one_pcfg(grammar, items[0], depth):\n",
    "            for frag2 in _generate_all_pcfg(grammar, items[1:], depth):\n",
    "                yield frag1 + frag2\n",
    "    else:\n",
    "        yield []\n",
    "\n",
    "\n",
    "def _generate_one_pcfg(grammar, item, depth):\n",
    "    if depth > 0:\n",
    "        if isinstance(item, Nonterminal):\n",
    "            productions = grammar.productions(lhs=item)\n",
    "            probs = [rule.prob() for rule in productions]\n",
    "\n",
    "            for prod in random.choices(productions, probs, k=depth):\n",
    "                yield from _generate_all_pcfg(grammar, prod.rhs(), depth - 1)\n",
    "        else:\n",
    "            yield [item]\n",
    "    else:\n",
    "        yield []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ll going even the new chip and had hurt The thing heading two . \n",
      "\n",
      "stories a friend descending of the way of his lyrics were a ground , much even shirt , `` her time \n",
      "\n",
      "not good \n",
      "\n",
      "stared very guess where her now fertile `` in a chest laughing from It n't . , n't likely , Her customer by she was Italy Hank never . , We born was his smell go stooped n't perfect but burning and eased At a light . -- '' the big shot be The recruited room side around along the careful scientist what my circles agrees He tell entirely white in the influx 's . and her words lined The . . \n",
      "\n",
      "him held \n",
      "\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    for string in generate_pcfg(pcfg, depth=100):\n",
    "        print(\" \".join(string), \"\\n\")\n",
    "        break\n",
    "        \n",
    "print('-'*100, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('grammars/nltk/nltk_pcfg.txt') as f:\n",
    "    raw_grammar = f.read()\n",
    "grammar = nltk_PCFG.fromstring(raw_grammar)\n",
    "\n",
    "grammar = create_lookup_probs(grammar)\n",
    "prod_productions_v2 = [rule for lhs in grammar._lhs_index.values() for rule in lhs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nltk.grammar.ProbabilisticProduction'>\n"
     ]
    }
   ],
   "source": [
    "print(type(prod_productions_v2[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************ Creating subset PCFG with top k = 0.1... ************\n",
      "Starting with 2513065 productions.\n",
      "Created subset PCFG with a length of 1290 productions.\n",
      "Cleaning subset: (1) removing unreachable productions...\n",
      "Amount of reachable nonterminals: 26\n",
      "Finished cleaning subset (1) left with 41 productions.\n",
      "Cleaning subset: (2) renormalizing probabilities...\n",
      "Finished cleaning subset (2)\n",
      "Cleaning subset: (3) adding POS tags...\n",
      "Finished cleaning subset (3)\n",
      "Write subset PCFG to pickle...\n",
      "Done\n",
      "************ Creating subset PCFG with top k = 1.0... ************\n",
      "Starting with 2513065 productions.\n",
      "Created subset PCFG with a length of 2509484 productions.\n",
      "Cleaning subset: (1) removing unreachable productions...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m0.2\u001b[39m, \u001b[38;5;241m0.3\u001b[39m, \u001b[38;5;241m0.4\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.6\u001b[39m, \u001b[38;5;241m0.7\u001b[39m, \u001b[38;5;241m0.8\u001b[39m, \u001b[38;5;241m0.9\u001b[39m]:\n\u001b[0;32m----> 2\u001b[0m     subset_pcfg, subset_pcfg_pos \u001b[38;5;241m=\u001b[39m \u001b[43mload_subset_pcfg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprod_productions_v2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     subset_corpus \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n",
      "Cell \u001b[0;32mIn[13], line 65\u001b[0m, in \u001b[0;36mload_subset_pcfg\u001b[0;34m(prob_productions, top_k)\u001b[0m\n\u001b[1;32m     61\u001b[0m         subset_pcfg_pos \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m subset_pcfg, subset_pcfg_pos\n\u001b[0;32m---> 65\u001b[0m subset_pcfg, subset_pcfg_pos \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_subset_pcfg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprob_productions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m subset_pcfg, subset_pcfg_pos\n",
      "Cell \u001b[0;32mIn[13], line 15\u001b[0m, in \u001b[0;36mcreate_subset_pcfg\u001b[0;34m(productions, top_k, no_recursion)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCreated subset PCFG with a length of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(subset_productions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m productions.\u001b[39m\u001b[38;5;124m'\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCleaning subset: (1) removing unreachable productions...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m final_subset_productions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreachable_productions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubset_productions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43mno_recursion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mno_recursion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# update set for removed recursive productions\u001b[39;00m\n\u001b[1;32m     24\u001b[0m reachable_nonterminals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(prod\u001b[38;5;241m.\u001b[39mlhs() \u001b[38;5;28;01mfor\u001b[39;00m prod \u001b[38;5;129;01min\u001b[39;00m final_subset_productions)\n",
      "Cell \u001b[0;32mIn[10], line 24\u001b[0m, in \u001b[0;36mreachable_productions\u001b[0;34m(productions, lhs, parents, no_recursion)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m rhs \u001b[38;5;129;01min\u001b[39;00m prod\u001b[38;5;241m.\u001b[39mrhs():\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rhs, Nonterminal):\n\u001b[0;32m---> 24\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m reachable_productions(\n\u001b[1;32m     25\u001b[0m             productions, \n\u001b[1;32m     26\u001b[0m             rhs, \n\u001b[1;32m     27\u001b[0m             parents\u001b[38;5;241m=\u001b[39mnew_parents,\n\u001b[1;32m     28\u001b[0m             no_recursion\u001b[38;5;241m=\u001b[39mno_recursion,\n\u001b[1;32m     29\u001b[0m         )\n",
      "Cell \u001b[0;32mIn[10], line 24\u001b[0m, in \u001b[0;36mreachable_productions\u001b[0;34m(productions, lhs, parents, no_recursion)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m rhs \u001b[38;5;129;01min\u001b[39;00m prod\u001b[38;5;241m.\u001b[39mrhs():\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rhs, Nonterminal):\n\u001b[0;32m---> 24\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m reachable_productions(\n\u001b[1;32m     25\u001b[0m             productions, \n\u001b[1;32m     26\u001b[0m             rhs, \n\u001b[1;32m     27\u001b[0m             parents\u001b[38;5;241m=\u001b[39mnew_parents,\n\u001b[1;32m     28\u001b[0m             no_recursion\u001b[38;5;241m=\u001b[39mno_recursion,\n\u001b[1;32m     29\u001b[0m         )\n",
      "    \u001b[0;31m[... skipping similar frames: reachable_productions at line 24 (5 times)]\u001b[0m\n",
      "Cell \u001b[0;32mIn[10], line 24\u001b[0m, in \u001b[0;36mreachable_productions\u001b[0;34m(productions, lhs, parents, no_recursion)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m rhs \u001b[38;5;129;01min\u001b[39;00m prod\u001b[38;5;241m.\u001b[39mrhs():\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rhs, Nonterminal):\n\u001b[0;32m---> 24\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m reachable_productions(\n\u001b[1;32m     25\u001b[0m             productions, \n\u001b[1;32m     26\u001b[0m             rhs, \n\u001b[1;32m     27\u001b[0m             parents\u001b[38;5;241m=\u001b[39mnew_parents,\n\u001b[1;32m     28\u001b[0m             no_recursion\u001b[38;5;241m=\u001b[39mno_recursion,\n\u001b[1;32m     29\u001b[0m         )\n",
      "Cell \u001b[0;32mIn[10], line 9\u001b[0m, in \u001b[0;36mreachable_productions\u001b[0;34m(productions, lhs, parents, no_recursion)\u001b[0m\n\u001b[1;32m      6\u001b[0m new_parents \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m*\u001b[39mparents, lhs)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# select productions belonging to the current lhs\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m lhs_productions \u001b[38;5;241m=\u001b[39m [prod \u001b[38;5;28;01mfor\u001b[39;00m prod \u001b[38;5;129;01min\u001b[39;00m productions \u001b[38;5;28;01mif\u001b[39;00m prod\u001b[38;5;241m.\u001b[39mlhs() \u001b[38;5;241m==\u001b[39m lhs]\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prod \u001b[38;5;129;01min\u001b[39;00m lhs_productions:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (prod,) \u001b[38;5;129;01min\u001b[39;00m PRODS_SEEN:\n",
      "Cell \u001b[0;32mIn[10], line 9\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      6\u001b[0m new_parents \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m*\u001b[39mparents, lhs)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# select productions belonging to the current lhs\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m lhs_productions \u001b[38;5;241m=\u001b[39m [prod \u001b[38;5;28;01mfor\u001b[39;00m prod \u001b[38;5;129;01min\u001b[39;00m productions \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mprod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlhs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlhs\u001b[49m]\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prod \u001b[38;5;129;01min\u001b[39;00m lhs_productions:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (prod,) \u001b[38;5;129;01min\u001b[39;00m PRODS_SEEN:\n",
      "File \u001b[0;32m~/Documents/Master/Jaar_3/Thesis/thesis_code/.venv/lib/python3.9/site-packages/nltk/grammar.py:123\u001b[0m, in \u001b[0;36mNonterminal.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03m    Return the node value corresponding to this ``Nonterminal``.\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \n\u001b[1;32m    119\u001b[0m \u001b[38;5;124;03m    :rtype: (any)\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_symbol\n\u001b[0;32m--> 123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m    124\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;124;03m    Return True if this non-terminal is equal to ``other``.  In\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;124;03m    particular, return True if ``other`` is a ``Nonterminal``\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03m    :rtype: bool\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mtype\u001b[39m(other) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_symbol \u001b[38;5;241m==\u001b[39m other\u001b[38;5;241m.\u001b[39m_symbol\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for k in [0.1, 1.0, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]:\n",
    "    subset_pcfg, subset_pcfg_pos = load_subset_pcfg(prod_productions_v2, top_k=k)\n",
    "    subset_corpus = []\n",
    "    n = 5\n",
    "    for _ in range(n):\n",
    "        for string in generate_pcfg(subset_pcfg, depth=100):\n",
    "            subset_corpus.append(\" \".join(string))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I smiled and opened his head . \n",
      "\n",
      "`` I <apostrophe>ll have done , <apostrophe><apostrophe> he said . \n",
      "\n",
      "I nodded and smiled . \n",
      "\n",
      "I put his head into the air and looked up into the door . \n",
      "\n",
      "`` I <apostrophe>ll be seen , <apostrophe><apostrophe> he said . \n",
      "\n",
      "`` I do n<apostrophe>t know , <apostrophe><apostrophe> he said . \n",
      "\n",
      "I held his head into the door and walked up into the door . \n",
      "\n",
      "I took a new thing into the ground and stopped . \n",
      "\n",
      "I stopped and gave his head into the ground . \n",
      "\n",
      "I looked on the room , keeping his head on the door . \n",
      "\n",
      "`` I do n<apostrophe>t know , <apostrophe><apostrophe> he said . \n",
      "\n",
      "`` I <apostrophe>ll see it if he was going to do , <apostrophe><apostrophe> he said . \n",
      "\n",
      "`` I do n<apostrophe>t know , <apostrophe><apostrophe> he said . \n",
      "\n",
      "I looked up into the room and raised his face . \n",
      "\n",
      "`` I <apostrophe>ll be done , <apostrophe><apostrophe> he said . \n",
      "\n",
      "`` I do n<apostrophe>t know , <apostrophe><apostrophe> he said . \n",
      "\n",
      "`` I <apostrophe>ll do it if he happens , <apostrophe><apostrophe> he said . \n",
      "\n",
      "I made his head into the window and felt a good look on the ground . \n",
      "\n",
      "I took his hand and took a little way into the floor . \n",
      "\n",
      "I said and went up on the room . \n",
      "\n",
      "I took his head , telling him on the ground . \n",
      "\n",
      "I felt a little time into the air , keeping his face into the wall . \n",
      "\n",
      "I looked up on the door , standing on the door . \n",
      "\n",
      "`` I do n<apostrophe>t want to say , <apostrophe><apostrophe> he said . \n",
      "\n",
      "`` I do n<apostrophe>t know , <apostrophe><apostrophe> he said . \n",
      "\n",
      "I looked up into the wall , looking on the ground . \n",
      "\n",
      "`` I <apostrophe>ll take a moment if he does , <apostrophe><apostrophe> he said . \n",
      "\n",
      "`` I <apostrophe>ll be gone , <apostrophe><apostrophe> he said . \n",
      "\n",
      "I looked into the window , putting his head on the door . \n",
      "\n",
      "`` I <apostrophe>ll be killed , <apostrophe><apostrophe> he said . \n",
      "\n",
      "I smiled and nodded . \n",
      "\n",
      "I smiled and stopped . \n",
      "\n",
      "I pulled his head into the room and grabbed his face . \n",
      "\n",
      "`` I do n<apostrophe>t know , <apostrophe><apostrophe> he said . \n",
      "\n",
      "`` I do n<apostrophe>t know , <apostrophe><apostrophe> he said . \n",
      "\n",
      "I sat on the water , keeping his head on the air . \n",
      "\n",
      "`` I do n<apostrophe>t know , <apostrophe><apostrophe> he said . \n",
      "\n",
      "I walked into the ground , making his face into the ground . \n",
      "\n",
      "I came up on the door , going on the room . \n",
      "\n",
      "I smiled and went up on the floor . \n",
      "\n",
      "`` I do n<apostrophe>t want to go , <apostrophe><apostrophe> he said . \n",
      "\n",
      "`` I do n<apostrophe>t worry , <apostrophe><apostrophe> he said . \n",
      "\n",
      "I smiled and said . \n",
      "\n",
      "`` I <apostrophe>ll have gone , <apostrophe><apostrophe> he said . \n",
      "\n",
      "I saw a good girl into the table , taking his head on the room . \n",
      "\n",
      "I gave his head on the window and walked up on the ground . \n",
      "\n",
      "`` I <apostrophe>ll have seen , <apostrophe><apostrophe> he said . \n",
      "\n",
      "I looked up into the wall and smiled . \n",
      "\n",
      "`` I <apostrophe>ll be seen , <apostrophe><apostrophe> he said . \n",
      "\n",
      "`` I <apostrophe>ll be told , <apostrophe><apostrophe> he said . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(50):\n",
    "    for string in generate_pcfg(subset_pcfg, depth=100):\n",
    "        print(\" \".join(string), \"\\n\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([ADVP, VBN, SQ, IN, PP, ``, WDT, S, INTJ, ADJP, DT, WP, WHADVP, PRP$, VB, :, WHNP, RP, TO, VBD, UH, VBP, SBARQ, PRT, VBZ, MD, WRB, ,, RB, FRAG, '', PRP, JJR, ., NP, SBAR, JJ, UCP, NNS, VP, NN, VBG, CC, NNP])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_pcfg._lhs_index.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
